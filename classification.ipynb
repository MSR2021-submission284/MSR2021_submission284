{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import javalang\n",
    "import re\n",
    "import sys\n",
    "import pyparsing\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pandas import DataFrame\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, splitext,split\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectKBest, f_classif, mutual_info_classif, chi2, f_regression, SelectFpr, SelectFdr\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "from anytree import Node, RenderTree, PreOrderIter, PostOrderIter, LevelOrderIter\n",
    "from anytree.exporter import DotExporter\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a method to calculate metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(Y_test,predicted_result):\n",
    "    c_matrix = confusion_matrix(Y_test,predicted_result)\n",
    "    print('confusion matrix:')\n",
    "    print(c_matrix)\n",
    "    tn = c_matrix[0,0]\n",
    "    fp = c_matrix[0,1]\n",
    "    fn = c_matrix[1,0]\n",
    "    tp = c_matrix[1,1]\n",
    "    \n",
    "    if ((tp + fp) == 0):\n",
    "        precision = 'not_defined'\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if ((tp + fn) == 0):\n",
    "        recall = 'not_defined'\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    \n",
    "    if (precision == 'not_defined' or recall == 'not_defined' or (precision + recall) == 0):\n",
    "        f1_score = 'not_defined'\n",
    "    else:\n",
    "        f1_score = (2 * precision * recall)/(precision + recall)\n",
    "        \n",
    "        \n",
    "    if ((fp + tn) == 0):\n",
    "        fp_rate = 'not_defined'\n",
    "    else:\n",
    "        fp_rate = fp / (fp + tn)\n",
    "\n",
    "    print('precision:',precision)\n",
    "    print('recall:',recall)\n",
    "    print('accuracy:',accuracy)\n",
    "    print('f1 score:',f1_score)\n",
    "    print('FP rate:',fp_rate)\n",
    "    return (precision,recall,accuracy,f1_score,fp_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the training accuracy and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variables(history):\n",
    "    training_accuracy = history.history['acc']\n",
    "    validation_accuracy = history.history['val_acc']\n",
    "    training_loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "    epochs = range(1,(epochs_num+1))\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "    plt.plot(epochs,training_accuracy,color='darkblue',label='training accuracy')\n",
    "    plt.plot(epochs,validation_accuracy,color='red',label='validation accuracy')\n",
    "    plt.title('Diagram of training accuracy and epochs',fontsize=16)\n",
    "    plt.xlabel('epochs',fontsize=14)\n",
    "    plt.ylabel('training accuracy',fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epochs,training_loss,color='darkblue',label='training loss')\n",
    "    plt.plot(epochs,validation_loss,color='red',label='validation loss')\n",
    "    plt.title('Diagram of training loss and epochs',fontsize=16)\n",
    "    plt.xlabel('epochs',fontsize=14)\n",
    "    plt.ylabel('training loss',fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_1(data_1,data_2):\n",
    "    length_1 = data_1.shape[1]-1\n",
    "    feature_1 = data_1[:,0:length_1]\n",
    "    feature = np.concatenate((feature_1,data_2),axis=1)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fp_r,tp_r):\n",
    "    plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    plt.plot(fp_r,tp_r)\n",
    "    plt.xlabel('FP rate')\n",
    "    plt.ylabel('TP rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold splittig the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf_data_split(data):\n",
    "    kf_data = []\n",
    "    kf_1 = KFold(n_splits = 10)\n",
    "    for train_i, test_i in kf_1.split(data):\n",
    "        train = data[train_i]\n",
    "        test = data[test_i]\n",
    "        kf_data.append([train,test])\n",
    "    return(kf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to binary array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(array_1):\n",
    "    array_2 = np.where(array_1>0,1,0)\n",
    "    return(array_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ROC-AUC and number of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_2(Y_test,predicted_result):\n",
    "    c_matrix = confusion_matrix(Y_test,predicted_result)\n",
    "    tn = c_matrix[0,0]\n",
    "    fp = c_matrix[0,1]\n",
    "    fn = c_matrix[1,0]\n",
    "    tp = c_matrix[1,1]\n",
    "    \n",
    "    if ((tp + fp) == 0):\n",
    "        precision = 'not_defined'\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if ((tp + fn) == 0):\n",
    "        recall = 'not_defined'\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "    \n",
    "    if (precision == 'not_defined' or recall == 'not_defined' or (precision + recall) == 0):\n",
    "        f1_score = 'not_defined'\n",
    "    else:\n",
    "        f1_score = (2 * precision * recall)/(precision + recall)\n",
    "        \n",
    "        \n",
    "    if ((fp + tn) == 0):\n",
    "        fp_rate = 'not_defined'\n",
    "    else:\n",
    "        fp_rate = fp / (fp + tn)\n",
    "\n",
    "    return (precision,recall,accuracy,f1_score,fp_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_3_2(train_1,test_1):\n",
    "    print('classification method: LR')\n",
    "    max_iter = 1000000\n",
    "    \n",
    "#     threshold = 0.1623\n",
    "      \n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    logistic_regression = LogisticRegression(random_state = 0)\n",
    "    model = logistic_regression.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted_r = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fp_r, tp_r, t_array = roc_curve(Y_test,predicted_r)\n",
    "    \n",
    "    auc_1 = roc_auc_score(Y_test,predicted_r)\n",
    "\n",
    "    length_2 = int(predicted_r.shape[0])\n",
    "    \n",
    "    predicted_result = np.zeros(length_2)\n",
    "    for i in range(length_2):\n",
    "        if (predicted_r[i] >= threshold):\n",
    "            predicted_result[i] = 1\n",
    "        else:\n",
    "            predicted_result[i] = 0\n",
    "    \n",
    "    Y_test = Y_test.astype(int)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics,auc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_classifier_3_2(train_1,test_1):\n",
    "    print('classification method: RF')\n",
    "#     threshold = 0.1623\n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=m_depth,random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    predicted_r = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fp_r, tp_r, t_array = roc_curve(Y_test,predicted_r)\n",
    "    \n",
    "    auc_1 = roc_auc_score(Y_test,predicted_r)\n",
    "\n",
    "    length_2 = int(predicted_r.shape[0])\n",
    "    \n",
    "    predicted_result = np.zeros(length_2)\n",
    "    for i in range(length_2):\n",
    "        if (predicted_r[i] >= threshold):\n",
    "            predicted_result[i] = 1\n",
    "        else:\n",
    "            predicted_result[i] = 0\n",
    "    \n",
    "    Y_test = Y_test.astype(int)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics,auc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KN_classifier_3_2(train_1,test_1):\n",
    "    print('classification method: KNN')\n",
    "#     threshold = 0.1623\n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    k_value = math.floor(math.sqrt(train_1.shape[0]))\n",
    "    if (k_value % 2 == 0):\n",
    "        k_value += 1\n",
    "    else:\n",
    "        start_val = 0\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors = k_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    predicted_r = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fp_r, tp_r, t_array = roc_curve(Y_test,predicted_r)\n",
    "    \n",
    "    auc_1 = roc_auc_score(Y_test,predicted_r)\n",
    "\n",
    "    length_2 = int(predicted_r.shape[0])\n",
    "    \n",
    "    predicted_result = np.zeros(length_2)\n",
    "    for i in range(length_2):\n",
    "        if (predicted_r[i] >= threshold):\n",
    "            predicted_result[i] = 1\n",
    "        else:\n",
    "            predicted_result[i] = 0\n",
    "    \n",
    "    Y_test = Y_test.astype(int)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics,auc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_NB_3_2(train_1,test_1):\n",
    "    print('classification method: GNB')\n",
    "#     threshold = 0.1623\n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    predicted_r = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fp_r, tp_r, t_array = roc_curve(Y_test,predicted_r)\n",
    "    \n",
    "    auc_1 = roc_auc_score(Y_test,predicted_r)\n",
    "\n",
    "    length_2 = int(predicted_r.shape[0])\n",
    "    \n",
    "    predicted_result = np.zeros(length_2)\n",
    "    for i in range(length_2):\n",
    "        if (predicted_r[i] >= threshold):\n",
    "            predicted_result[i] = 1\n",
    "        else:\n",
    "            predicted_result[i] = 0\n",
    "    \n",
    "    Y_test = Y_test.astype(int)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics,auc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_B_C_3_2(train_1,test_1):\n",
    "    print('classification method: Gradient Boosting Classifier')\n",
    "#     threshold = 0.1623\n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    clf = GradientBoostingClassifier(learning_rate=1.0,max_depth=m_depth,random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    predicted_r = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fp_r, tp_r, t_array = roc_curve(Y_test,predicted_r)\n",
    "    \n",
    "    auc_1 = roc_auc_score(Y_test,predicted_r)\n",
    "\n",
    "    length_2 = int(predicted_r.shape[0])\n",
    "    \n",
    "    predicted_result = np.zeros(length_2)\n",
    "    for i in range(length_2):\n",
    "        if (predicted_r[i] >= threshold):\n",
    "            predicted_result[i] = 1\n",
    "        else:\n",
    "            predicted_result[i] = 0\n",
    "    \n",
    "    Y_test = Y_test.astype(int)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics,auc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ada_B_3_2(train_1,test_1):\n",
    "    print('classification method: Ada B')\n",
    "#     threshold = 0.1623\n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    predicted_r = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fp_r, tp_r, t_array = roc_curve(Y_test,predicted_r)\n",
    "    \n",
    "    auc_1 = roc_auc_score(Y_test,predicted_r)\n",
    "\n",
    "    length_2 = int(predicted_r.shape[0])\n",
    "    \n",
    "    predicted_result = np.zeros(length_2)\n",
    "    for i in range(length_2):\n",
    "        if (predicted_r[i] >= threshold):\n",
    "            predicted_result[i] = 1\n",
    "        else:\n",
    "            predicted_result[i] = 0\n",
    "    \n",
    "    Y_test = Y_test.astype(int)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics,auc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_3_2(train_1,test_1):\n",
    "    print('classification method: linear SVM')\n",
    "#     threshold = 0.1623\n",
    "    length = train_1.shape[1] - 1\n",
    "    X_train = train_1[:,0:length]\n",
    "    Y_train = train_1[:,length]\n",
    "    X_test = test_1[:,0:length]\n",
    "    Y_test = test_1[:,length]\n",
    "    \n",
    "    clf = SGDClassifier(loss='hinge',max_iter=1000,random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted_result = clf.predict(X_test)\n",
    "    computed_metrics = compute_metrics_2(Y_test,predicted_result)\n",
    "    return computed_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_subset(data_1,c):\n",
    "    start_time = time.time()\n",
    "    if (c == 1):\n",
    "        new_d = select_features_2(data_1,400,7)[0]\n",
    "    elif (c == 2):\n",
    "        new_d = select_features_2(data_1,400,8)[0]\n",
    "    elif (c == 4):\n",
    "        new_d = select_features_2(data_1,400,10)[0]\n",
    "    finish_time = time.time()\n",
    "    elapsed_time = finish_time - start_time\n",
    "    print(elapsed_time)\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1:LR,   2:RF,   9:KNN,   10:GNB\n",
    "c1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = 25\n",
    "d_1_p_2 = select_data_subset(d_1_p,c1)\n",
    "d_1_c_2 = select_data_subset(d_1_c,c1)\n",
    "\n",
    "step_value = 25\n",
    "d_2_p_2 = select_data_subset(d_2_p,c1)\n",
    "d_2_c_2 = select_data_subset(d_2_c,c1)\n",
    "\n",
    "step_value = 25\n",
    "d_3_p_2 = select_data_subset(d_3_p,c1)\n",
    "d_3_c_2 = select_data_subset(d_3_c,c1)\n",
    "\n",
    "step_value = 25\n",
    "d_4_p_2 = select_data_subset(d_4_p,c1)\n",
    "d_4_c_2 = select_data_subset(d_4_c,c1)\n",
    "\n",
    "step_value = 25\n",
    "d_5_p_2 = select_data_subset(d_5_p,c1)\n",
    "d_5_c_2 = select_data_subset(d_5_c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = 25\n",
    "d_1_p_2 = select_data_subset(d_1_p,c1)\n",
    "d_1_c_2 = select_data_subset(d_1_c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = 25\n",
    "d_2_p_2 = select_data_subset(d_2_p,c1)\n",
    "d_2_c_2 = select_data_subset(d_2_c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = 25\n",
    "d_3_p_2 = select_data_subset(d_3_p,c1)\n",
    "d_3_c_2 = select_data_subset(d_3_c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = 25\n",
    "d_4_p_2 = select_data_subset(d_4_p,c1)\n",
    "d_4_c_2 = select_data_subset(d_4_c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = 25\n",
    "d_5_p_2 = select_data_subset(d_5_p,c1)\n",
    "d_5_c_2 = select_data_subset(d_5_c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data_2/dense_trigram_data_AST1_LR.npy',d_1_p_2)\n",
    "np.save('./data_2/dense_trigram_data_c_AST1_LR.npy',d_1_c_2)\n",
    "\n",
    "np.save('./data_2/dense_trigram_data_AST2_LR.npy',d_2_p_2)\n",
    "np.save('./data_2/dense_trigram_data_c_AST2_LR.npy',d_2_c_2)\n",
    "\n",
    "np.save('./data_2/dense_trigram_data_AST3_LR.npy',d_3_p_2)\n",
    "np.save('./data_2/dense_trigram_data_c_AST3_LR.npy',d_3_c_2)\n",
    "\n",
    "np.save('./data_2/dense_trigram_data_AST4_LR.npy',d_4_p_2)\n",
    "np.save('./data_2/dense_trigram_data_c_AST4_LR.npy',d_4_c_2)\n",
    "\n",
    "np.save('./data_2/dense_trigram_data_word_LR.npy',d_5_p_2)\n",
    "np.save('./data_2/dense_trigram_data_c_word_LR.npy',d_5_c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1_p_2 = np.load('./data_2/dense_trigram_data_AST1_LR.npy')\n",
    "d_1_c_2 = np.load('./data_2/dense_trigram_data_c_AST1_LR.npy')\n",
    "\n",
    "d_2_p_2 = np.load('./data_2/dense_trigram_data_AST2_LR.npy')\n",
    "d_2_c_2 = np.load('./data_2/dense_trigram_data_c_AST2_LR.npy')\n",
    "\n",
    "d_3_p_2 = np.load('./data_2/dense_trigram_data_AST3_LR.npy')\n",
    "d_3_c_2 = np.load('./data_2/dense_trigram_data_c_AST3_LR.npy')\n",
    "\n",
    "d_4_p_2 = np.load('./data_2/dense_trigram_data_AST4_LR.npy')\n",
    "d_4_c_2 = np.load('./data_2/dense_trigram_data_c_AST4_LR.npy')\n",
    "\n",
    "d_5_p_2 = np.load('./data_2/dense_trigram_data_word_LR.npy')\n",
    "d_5_c_2 = np.load('./data_2/dense_trigram_data_c_word_LR.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing the data into fixed sets of test and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_2(data):\n",
    "    l_1 =data.shape[0]\n",
    "    l_2 = int(np.ceil(l_1 / 5))\n",
    "    random.seed(10)\n",
    "    index_list = random.sample(range(l_1),l_2)\n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    for i in range(l_1):\n",
    "        if i in index_list:\n",
    "            test_data.append(data[i])\n",
    "        else:\n",
    "            train_data.append(data[i])\n",
    "    test_data = np.array(test_data)\n",
    "    train_data = np.array(train_data)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2_p, test_2_p = split_data_2(d_2_p)\n",
    "train_2_c, test_2_c = split_data_2(d_2_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_2(data,k_value,score_f):\n",
    "    length = data.shape[1] - 1\n",
    "    print('Primary number of features:',length)\n",
    "    X = data[:,0:length]\n",
    "    y = data[:,length].reshape(-1,1)\n",
    "    \n",
    "    if (score_f <= 5):\n",
    "        if (score_f == 1):\n",
    "            s = SelectKBest(score_func=f_classif, k=k_value)\n",
    "        elif (score_f == 2):\n",
    "            s = SelectKBest(score_func=chi2, k=k_value)\n",
    "        elif (score_f == 3):\n",
    "            s = SelectKBest(score_func=mutual_info_classif, k=k_value)\n",
    "        elif (score_f == 4):\n",
    "            s = SelectFpr(score_func=chi2, alpha=0.01)\n",
    "        elif (score_f == 5):\n",
    "            s = SelectFdr(score_func=chi2, alpha=0.01)\n",
    "         \n",
    "        start_time = time.time()\n",
    "        new_X = s.fit_transform(X,y)\n",
    "        finish_time = time.time()\n",
    "        elapsed_time = finish_time - start_time\n",
    "        \n",
    "        columns = s.get_support(indices=True)\n",
    "        scores = s.scores_[s.get_support()]\n",
    "        new_data = np.hstack((new_X,y))\n",
    "\n",
    "        zipped_f = zip(scores,columns)\n",
    "        zipped_f = sorted(zipped_f,reverse=True)\n",
    "        sorted_columns = [column for (score,column) in zipped_f]\n",
    "    else:\n",
    "        if (score_f == 6):\n",
    "            estimator = SVR(kernel = \"linear\")\n",
    "        elif (score_f == 7):\n",
    "            estimator = LogisticRegression(random_state = 0)\n",
    "            print('LR','step_value:',step_value)\n",
    "        elif (score_f == 8):\n",
    "            estimator = RandomForestClassifier(max_depth=m_depth,random_state=0)\n",
    "            print('RF','step_value:',step_value)\n",
    "        elif (score_f == 10):\n",
    "            estimator = GaussianNB()\n",
    "            print('GNB','step_value:',step_value)\n",
    "        elif (score_f == 12):\n",
    "            estimator = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
    "            print('Ada_B','step_value:',step_value)\n",
    "        \n",
    "        s = RFE(estimator,n_features_to_select=k_value,step=step_value)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        new_X = s.fit_transform(X,y)\n",
    "        finish_time = time.time()\n",
    "        elapsed_time = finish_time - start_time\n",
    "        \n",
    "        columns = s.get_support(indices=True)\n",
    "        new_data = np.hstack((new_X,y))\n",
    "    \n",
    "    return new_data,columns,elapsed_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_result(train_2,test_2,c):\n",
    "    if (c == 1):\n",
    "        r = logistic_regression_3_2(train_2,test_2)\n",
    "    elif (c == 2):\n",
    "        r = RF_classifier_3_2(train_2,test_2)\n",
    "    elif (c == 4):\n",
    "        r = G_NB_3_2(train_2,test_2)\n",
    "    elif (c == 5):\n",
    "        r = Gradient_B_C_3_2(train_2,test_2)\n",
    "    elif (c == 6):\n",
    "        r = Ada_B_3_2(train_2,test_2)\n",
    "    elif (c == 7):\n",
    "        r = SVM_3_2(train_2,test_2)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_RFE(data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,data_10,c_method):\n",
    "    d_1 =data_1.copy()\n",
    "    d_2 =data_2.copy()\n",
    "    d_3 =data_3.copy()\n",
    "    d_4 =data_4.copy()\n",
    "    d_5 =data_5.copy()\n",
    "    d_6 =data_6.copy()\n",
    "    d_7 =data_7.copy()\n",
    "    d_8 =data_8.copy()\n",
    "    d_9 =data_9.copy()\n",
    "    d_10 =data_10.copy()\n",
    "    \n",
    "    train_1_p, test_1_p = split_data_2(d_1)\n",
    "    train_1_c, test_1_c = split_data_2(d_2)\n",
    "\n",
    "    train_2_p, test_2_p = split_data_2(d_3)\n",
    "    train_2_c, test_2_c = split_data_2(d_4)\n",
    "\n",
    "    train_3_p, test_3_p = split_data_2(d_5)\n",
    "    train_3_c, test_3_c = split_data_2(d_6)\n",
    "\n",
    "    train_4_p, test_4_p = split_data_2(d_7)\n",
    "    train_4_c, test_4_c = split_data_2(d_8)\n",
    "\n",
    "    train_5_p, test_5_p = split_data_2(d_9)\n",
    "    train_5_c, test_5_c = split_data_2(d_10)\n",
    "\n",
    "\n",
    "    features_n = []\n",
    "    \n",
    "    auc_array_p_AST1 = []\n",
    "    auc_array_c_AST1 = []\n",
    "    auc_array_b_AST1 = []\n",
    "    \n",
    "    auc_array_p_AST2 = []\n",
    "    auc_array_c_AST2 = []\n",
    "    auc_array_b_AST2 = []\n",
    "    \n",
    "    auc_array_p_AST3 = []\n",
    "    auc_array_c_AST3 = []\n",
    "    auc_array_b_AST3 = []\n",
    "    \n",
    "    auc_array_p_AST4 = []\n",
    "    auc_array_c_AST4 = []\n",
    "    auc_array_b_AST4 = []\n",
    "    \n",
    "    auc_array_p_word = []\n",
    "    auc_array_c_word = []\n",
    "    auc_array_b_word = []\n",
    "\n",
    "\n",
    "    if (c_method == 1):\n",
    "        score_f_type = 7\n",
    "    elif (c_method == 2):\n",
    "        score_f_type = 8\n",
    "    elif (c_method == 4):\n",
    "        score_f_type = 10\n",
    "    elif (c_method == 6):\n",
    "        score_f_type = 12\n",
    "    \n",
    "    i_max = 500\n",
    "    for i in range(i_max,24,-25):\n",
    "        print(i)\n",
    "        features_n.append(i)\n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_1_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_p = feature_s[0]\n",
    "        length_1 = test_1_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_p = test_1_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_1_p,test_1_p,c_method)[1]\n",
    "        auc_array_p_AST1.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST1_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "            \n",
    "        feature_s = select_features_2(train_1_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_c = feature_s[0]\n",
    "        length_1 = test_1_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_c = test_1_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_1_c,test_1_c,c_method)[1]\n",
    "        auc_array_c_AST1.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST1_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_1_c_2 = train_1_c.copy()\n",
    "        test_1_c_2 = test_1_c.copy()\n",
    "        b_train_data = convert_to_binary(train_1_c_2)\n",
    "        b_test_data = convert_to_binary(test_1_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST1.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_2_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_p = feature_s[0]\n",
    "        length_1 = test_2_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_p = test_2_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_2_p,test_2_p,c_method)[1]\n",
    "        auc_array_p_AST2.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST2_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_2_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_c = feature_s[0]\n",
    "        length_1 = test_2_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_c = test_2_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_2_c,test_2_c,c_method)[1]\n",
    "        auc_array_c_AST2.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST2_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_2_c_2 = train_2_c.copy()\n",
    "        test_2_c_2 = test_2_c.copy()\n",
    "        b_train_data = convert_to_binary(train_2_c_2)\n",
    "        b_test_data = convert_to_binary(test_2_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST2.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_3_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_p = feature_s[0]\n",
    "        length_1 = test_3_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_p = test_3_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_3_p,test_3_p,c_method)[1]\n",
    "        auc_array_p_AST3.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST3_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_3_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_c = feature_s[0]\n",
    "        length_1 = test_3_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_c = test_3_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_3_c,test_3_c,c_method)[1]\n",
    "        auc_array_c_AST3.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST3_c')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_3_c_2 = train_3_c.copy()\n",
    "        test_3_c_2 = test_3_c.copy()\n",
    "        b_train_data = convert_to_binary(train_3_c_2)\n",
    "        b_test_data = convert_to_binary(test_3_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST3.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_4_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_p = feature_s[0]\n",
    "        length_1 = test_4_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_p = test_4_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_4_p,test_4_p,c_method)[1]\n",
    "        auc_array_p_AST4.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST4_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_4_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_c = feature_s[0]\n",
    "        length_1 = test_4_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_c = test_4_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_4_c,test_4_c,c_method)[1]\n",
    "        auc_array_c_AST4.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST4_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_4_c_2 = train_4_c.copy()\n",
    "        test_4_c_2 = test_4_c.copy()\n",
    "        b_train_data = convert_to_binary(train_4_c_2)\n",
    "        b_test_data = convert_to_binary(test_4_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST4.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_5_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_5_p = feature_s[0]\n",
    "        length_1 = test_5_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_5_p = test_5_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_5_p,test_5_p,c_method)[1]\n",
    "        auc_array_p_word.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('Word_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "            \n",
    "        feature_s = select_features_2(train_5_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_5_c = feature_s[0]\n",
    "        length_1 = test_5_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_5_c = test_5_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_5_c,test_5_c,c_method)[1]\n",
    "        auc_array_c_word.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('Word_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_5_c_2 = train_5_c.copy()\n",
    "        test_5_c_2 = test_5_c.copy()\n",
    "        b_train_data = convert_to_binary(train_5_c_2)\n",
    "        b_test_data = convert_to_binary(test_5_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_word.append(auc_value_b)\n",
    "            \n",
    "    return(features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AST4\n",
    "def Evaluation_RFE_3(data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,data_10,c_method):\n",
    "    d_1 =data_1.copy()\n",
    "    d_2 =data_2.copy()\n",
    "    d_3 =data_3.copy()\n",
    "    d_4 =data_4.copy()\n",
    "    d_5 =data_5.copy()\n",
    "    d_6 =data_6.copy()\n",
    "    d_7 =data_7.copy()\n",
    "    d_8 =data_8.copy()\n",
    "    d_9 =data_9.copy()\n",
    "    d_10 =data_10.copy()\n",
    "    \n",
    "    train_1_p, test_1_p = split_data_2(d_1)\n",
    "    train_1_c, test_1_c = split_data_2(d_2)\n",
    "\n",
    "    train_2_p, test_2_p = split_data_2(d_3)\n",
    "    train_2_c, test_2_c = split_data_2(d_4)\n",
    "\n",
    "    train_3_p, test_3_p = split_data_2(d_5)\n",
    "    train_3_c, test_3_c = split_data_2(d_6)\n",
    "\n",
    "    train_4_p, test_4_p = split_data_2(d_7)\n",
    "    train_4_c, test_4_c = split_data_2(d_8)\n",
    "\n",
    "    train_5_p, test_5_p = split_data_2(d_9)\n",
    "    train_5_c, test_5_c = split_data_2(d_10)\n",
    "\n",
    "\n",
    "    features_n = []\n",
    "    \n",
    "    auc_array_p_AST1 = []\n",
    "    auc_array_c_AST1 = []\n",
    "    auc_array_b_AST1 = []\n",
    "    \n",
    "    auc_array_p_AST2 = []\n",
    "    auc_array_c_AST2 = []\n",
    "    auc_array_b_AST2 = []\n",
    "    \n",
    "    auc_array_p_AST3 = []\n",
    "    auc_array_c_AST3 = []\n",
    "    auc_array_b_AST3 = []\n",
    "    \n",
    "    auc_array_p_AST4 = []\n",
    "    auc_array_c_AST4 = []\n",
    "    auc_array_b_AST4 = []\n",
    "    \n",
    "    auc_array_p_word = []\n",
    "    auc_array_c_word = []\n",
    "    auc_array_b_word = []\n",
    "\n",
    "\n",
    "    \n",
    "    if (c_method == 1):\n",
    "        score_f_type = 7\n",
    "    elif (c_method == 2):\n",
    "        score_f_type = 8\n",
    "    elif (c_method == 4):\n",
    "        score_f_type = 10\n",
    "    elif (c_method == 6):\n",
    "        score_f_type = 12\n",
    "    \n",
    "    i_max = 500\n",
    "    for i in range(i_max,24,-25):\n",
    "        print(i)\n",
    "        features_n.append(i)\n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_4_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_p = feature_s[0]\n",
    "        length_1 = test_4_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_p = test_4_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_4_p,test_4_p,c_method)[1]\n",
    "        auc_array_p_AST4.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST4_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_4_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_c = feature_s[0]\n",
    "        length_1 = test_4_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_c = test_4_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_4_c,test_4_c,c_method)[1]\n",
    "        auc_array_c_AST4.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST4_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_4_c_2 = train_4_c.copy()\n",
    "        test_4_c_2 = test_4_c.copy()\n",
    "        b_train_data = convert_to_binary(train_4_c_2)\n",
    "        b_test_data = convert_to_binary(test_4_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST4.append(auc_value_b)\n",
    "        \n",
    "            \n",
    "    return(features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Logistic Regression\n",
    "step_value = 25\n",
    "result = Evaluation_RFE(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Logistic Regression\n",
    "step_value = 25\n",
    "result = Evaluation_RFE(b_1_p, b_1_c, b_2_p, b_2_c, b_3_p, b_3_c, b_4_p, b_4_c, b_5_p, b_5_c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Random Forest\n",
    "step_value = 25\n",
    "m_depth = 10\n",
    "result = Evaluation_RFE(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE  Logistic Regression AST4\n",
    "step_value = 25\n",
    "result = Evaluation_RFE_3(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE  Random Forest AST4\n",
    "step_value = 25\n",
    "m_depth = 10\n",
    "result = Evaluation_RFE_3(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE  GNB AST4\n",
    "step_value = 25\n",
    "result = Evaluation_RFE_3(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Ada_B AST4\n",
    "step_value = 25\n",
    "result = Evaluation_RFE_3(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_2/results/poi_GNB_trigrams_chi2.txt\",\"rb\") as fp:\n",
    "    result = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_names = ['features','AST1_p','AST1_c','AST1_b','AST2_p','AST2_c','AST2_b','AST3_p','AST3_c','AST3_b','AST4_p','AST4_c','AST4_b','Word_p','Word_c','Word_b']\n",
    "for i in range(len(result)):\n",
    "    print(r_names[i])\n",
    "    print(round(np.mean(result[i]),4))\n",
    "    print(round(np.std(result[i]),4),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    " \n",
    "plt.plot(features_n,auc_array_p_AST1,color='magenta',marker='o',markersize=5,label='Level-order AST, probability')\n",
    "plt.plot(features_n,auc_array_c_AST1,color='magenta',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Level-order AST, count')\n",
    "plt.plot(features_n,auc_array_b_AST1,color='magenta',marker='o',markersize=5,linestyle='dotted',label='Level-order AST, binary')\n",
    "\n",
    "plt.plot(features_n,auc_array_p_AST2,color='grey',marker='o',markersize=5,label='Pre-order AST, probability')\n",
    "plt.plot(features_n,auc_array_c_AST2,color='grey',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Pre-order AST, count')\n",
    "plt.plot(features_n,auc_array_b_AST2,color='grey',marker='o',markersize=5,linestyle='dotted',label='Pre-order AST, binary')\n",
    "\n",
    "plt.plot(features_n,auc_array_p_AST3,color='firebrick',marker='o',markersize=5,label='Post-order AST, probability')\n",
    "plt.plot(features_n,auc_array_c_AST3,color='firebrick',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Post-order AST, count')\n",
    "plt.plot(features_n,auc_array_b_AST3,color='firebrick',marker='o',markersize=5,linestyle='dotted',label='Post-order AST, binary')\n",
    "\n",
    "plt.plot(features_n,auc_array_p_AST4,color='blue',marker='o',markersize=5,label='Path-based AST, probability')\n",
    "plt.plot(features_n,auc_array_c_AST4,color='blue',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Path-based AST, count')\n",
    "plt.plot(features_n,auc_array_b_AST4,color='blue',marker='o',markersize=5,linestyle='dotted',label='Path-based AST, binary')\n",
    "\n",
    "plt.plot(features_n,auc_array_p_word,color='black',marker='o',markersize=5,label='Word level, probability')\n",
    "plt.plot(features_n,auc_array_c_word,color='black',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Word level, count')\n",
    "plt.plot(features_n,auc_array_b_word,color='black',marker='o',markersize=5,linestyle='dotted',label='Word level, binary')\n",
    "\n",
    "plt.title('AUC per number of features',fontsize=16)\n",
    "plt.xlabel('Number of features',fontsize=14)\n",
    "plt.ylabel('AUC',fontsize=14)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.5,1])\n",
    "plt.gca().legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_2/results/poi_RF_trigrams_FE_AST4.txt\",\"wb\") as fp:\n",
    "    pickle.dump(results_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data_2/results/poi_Ada_B_trigrams_FE_AST4.txt\",\"rb\") as fp:\n",
    "    result = pickle.load(fp)\n",
    "print(result,len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi2 evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_chi2(data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,data_10,c_method):\n",
    "    d_1 =data_1.copy()\n",
    "    d_2 =data_2.copy()\n",
    "    d_3 =data_3.copy()\n",
    "    d_4 =data_4.copy()\n",
    "    d_5 =data_5.copy()\n",
    "    d_6 =data_6.copy()\n",
    "    d_7 =data_7.copy()\n",
    "    d_8 =data_8.copy()\n",
    "    d_9 =data_9.copy()\n",
    "    d_10 =data_10.copy()\n",
    "    \n",
    "    train_1_p, test_1_p = split_data_2(d_1)\n",
    "    train_1_c, test_1_c = split_data_2(d_2)\n",
    "\n",
    "    train_2_p, test_2_p = split_data_2(d_3)\n",
    "    train_2_c, test_2_c = split_data_2(d_4)\n",
    "\n",
    "    train_3_p, test_3_p = split_data_2(d_5)\n",
    "    train_3_c, test_3_c = split_data_2(d_6)\n",
    "\n",
    "    train_4_p, test_4_p = split_data_2(d_7)\n",
    "    train_4_c, test_4_c = split_data_2(d_8)\n",
    "\n",
    "    train_5_p, test_5_p = split_data_2(d_9)\n",
    "    train_5_c, test_5_c = split_data_2(d_10)\n",
    "\n",
    "\n",
    "    features_n = []\n",
    "    \n",
    "    auc_array_p_AST1 = []\n",
    "    auc_array_c_AST1 = []\n",
    "    auc_array_b_AST1 = []\n",
    "    \n",
    "    auc_array_p_AST2 = []\n",
    "    auc_array_c_AST2 = []\n",
    "    auc_array_b_AST2 = []\n",
    "    \n",
    "    auc_array_p_AST3 = []\n",
    "    auc_array_c_AST3 = []\n",
    "    auc_array_b_AST3 = []\n",
    "    \n",
    "    auc_array_p_AST4 = []\n",
    "    auc_array_c_AST4 = []\n",
    "    auc_array_b_AST4 = []\n",
    "    \n",
    "    auc_array_p_word = []\n",
    "    auc_array_c_word = []\n",
    "    auc_array_b_word = []\n",
    "\n",
    "    score_f_type = 2\n",
    "    \n",
    "    print('Start training')\n",
    "    feature_s_1 = select_features_2(train_5_p,400,score_f_type)\n",
    "    print('Stop training')\n",
    "    \n",
    "    i_max = 400\n",
    "    for i in range(i_max,24,-25):\n",
    "        print(i)\n",
    "        features_n.append(i)\n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_1_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_p_2 = feature_s[0]\n",
    "        length_1 = test_1_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_p_2 = test_1_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_1_p_2,test_1_p_2,c_method)[1]\n",
    "        auc_array_p_AST1.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST1_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_1_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_c_2 = feature_s[0]\n",
    "        length_1 = test_1_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_c_2 = test_1_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_1_c_2,test_1_c_2,c_method)[1]\n",
    "        auc_array_c_AST1.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST1_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_1_c_3 = train_1_c_2.copy()\n",
    "        test_1_c_3 = test_1_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_1_c_3)\n",
    "        b_test_data = convert_to_binary(test_1_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST1.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_2_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_p_2 = feature_s[0]\n",
    "        length_1 = test_2_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_p_2 = test_2_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_2_p_2,test_2_p_2,c_method)[1]\n",
    "        auc_array_p_AST2.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST2_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_2_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_c_2 = feature_s[0]\n",
    "        length_1 = test_2_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_c_2 = test_2_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_2_c_2,test_2_c_2,c_method)[1]\n",
    "        auc_array_c_AST2.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST2_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_2_c_3 = train_2_c_2.copy()\n",
    "        test_2_c_3 = test_2_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_2_c_3)\n",
    "        b_test_data = convert_to_binary(test_2_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST2.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_3_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_p_2 = feature_s[0]\n",
    "        length_1 = test_3_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_p_2 = test_3_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_3_p_2,test_3_p_2,c_method)[1]\n",
    "        auc_array_p_AST3.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST3_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_3_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_c_2 = feature_s[0]\n",
    "        length_1 = test_3_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_c_2 = test_3_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_3_c_2,test_3_c_2,c_method)[1]\n",
    "        auc_array_c_AST3.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST3_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_3_c_3 = train_3_c_2.copy()\n",
    "        test_3_c_3 = test_3_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_3_c_3)\n",
    "        b_test_data = convert_to_binary(test_3_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST3.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_4_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_p_2 = feature_s[0]\n",
    "        length_1 = test_4_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_p_2 = test_4_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_4_p_2,test_4_p_2,c_method)[1]\n",
    "        auc_array_p_AST4.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('AST4_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_4_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_c_2 = feature_s[0]\n",
    "        length_1 = test_4_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_c_2 = test_4_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_4_c_2,test_4_c_2,c_method)[1]\n",
    "        auc_array_c_AST4.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('AST4_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_4_c_3 = train_4_c_2.copy()\n",
    "        test_4_c_3 = test_4_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_4_c_3)\n",
    "        b_test_data = convert_to_binary(test_4_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_AST4.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_5_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_5_p_2 = feature_s[0]\n",
    "        length_1 = test_5_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_5_p_2 = test_5_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_5_p_2,test_5_p_2,c_method)[1]\n",
    "        auc_array_p_word.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('Word_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "            \n",
    "        feature_s = select_features_2(train_5_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_5_c_2 = feature_s[0]\n",
    "        length_1 = test_5_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_5_c_2 = test_5_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_5_c_2,test_5_c_2,c_method)[1]\n",
    "        auc_array_c_word.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('Word_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_5_c_3 = train_5_c_2.copy()\n",
    "        test_5_c_3 = test_5_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_5_c_3)\n",
    "        b_test_data = convert_to_binary(test_5_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_word.append(auc_value_b)\n",
    "            \n",
    "    return(features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:LR, 2:RF, 4:GNB, 5:Gradient_B_C, 6: Ada-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Logistic Regression\n",
    "step_value = 25\n",
    "result = Evaluation_chi2(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Logistic Regression\n",
    "step_value = 25\n",
    "result = Evaluation_chi2(b_1_p, b_1_c, b_2_p, b_2_c, b_3_p, b_3_c, b_4_p, b_4_c, b_5_p, b_5_c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Logistic Regression (bigrams)\n",
    "step_value = 25\n",
    "result = Evaluation_chi2(b_1_p, b_1_c, b_2_p, b_2_c, b_3_p, b_3_c, b_4_p, b_4_c, b_5_p, b_5_c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Random Forest\n",
    "step_value = 25\n",
    "m_depth = 10\n",
    "result = Evaluation_chi2(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Gaussian Naive Bayes\n",
    "step_value = 25\n",
    "result = Evaluation_chi2(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Gradient Boosting Classifier\n",
    "step_value = 25\n",
    "m_depth = 1\n",
    "result = Evaluation_chi2(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Ada Boost Classifier\n",
    "step_value = 25\n",
    "result = Evaluation_chi2(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_RFE_2(data_1,data_2,c_method):\n",
    "    d_1 = data_1.copy()\n",
    "    d_2 = data_2.copy()\n",
    "    \n",
    "    train_1_p, test_1_p = split_data_2(d_1)\n",
    "    train_1_c, test_1_c = split_data_2(d_2)\n",
    "\n",
    "    features_n = []\n",
    "    \n",
    "    auc_array_p = []\n",
    "    auc_array_c = []\n",
    "    auc_array_b = []\n",
    "    \n",
    "    if (c_method == 1):\n",
    "        score_f_type = 7\n",
    "    elif (c_method == 2):\n",
    "        score_f_type = 8\n",
    "    \n",
    "    i_max = 500\n",
    "    for i in range(i_max,24,-25):\n",
    "        print(i)\n",
    "        features_n.append(i)\n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_1_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_p = feature_s[0]\n",
    "        length_1 = test_1_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_p = test_1_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_1_p,test_1_p,c_method)[1]\n",
    "        auc_array_p.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "            \n",
    "        feature_s = select_features_2(train_1_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_c = feature_s[0]\n",
    "        length_1 = test_1_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_c = test_1_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_1_c,test_1_c,c_method)[1]\n",
    "        auc_array_c.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_1_c_2 = train_1_c.copy()\n",
    "        test_1_c_2 = test_1_c.copy()\n",
    "        b_train_data = convert_to_binary(train_1_c_2)\n",
    "        b_test_data = convert_to_binary(test_1_c_2)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b.append(auc_value_b)\n",
    "            \n",
    "    return(features_n,auc_array_p,auc_array_c,auc_array_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Logistic Regression\n",
    "step_value = 25\n",
    "result_2 = Evaluation_RFE_2(new_data_p,new_data_c,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n,auc_array_p_concatenated,auc_array_c_concatenated,auc_array_b_concatenated = result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_p = c_1(b_4_p,d_4_p)\n",
    "print(new_data_p.shape)\n",
    "\n",
    "new_data_c = c_1(b_4_c,d_4_c)\n",
    "print(new_data_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_p = c_1(c_1(b_4_p,d_4_p),c_1(b_5_p,d_5_p))\n",
    "print(new_data_p.shape)\n",
    "\n",
    "new_data_c = c_1(c_1(b_4_c,d_4_c),c_1(b_5_c,d_5_c))\n",
    "print(new_data_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_fs(d_1,c_method):\n",
    "    train_1, test_1 = split_data_2(d_1)\n",
    "    start_time = time.time()\n",
    "    result_2 = classification_result(train_1,test_1,c_method)\n",
    "    finish_time = time.time()\n",
    "    elapsed_time = finish_time - start_time\n",
    "    print(round(elapsed_time,4))\n",
    "    return result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_depth = 10\n",
    "without_fs_result = without_fs(d_1_p,2)\n",
    "print(without_fs_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KF-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_result_2(train_2,test_2,c):\n",
    "    if (c == 1):\n",
    "        start_time = time.time()\n",
    "        r = logistic_regression_3_2(train_2,test_2)\n",
    "        finish_time = time.time()\n",
    "    elif (c == 2):\n",
    "        start_time = time.time()\n",
    "        r = RF_classifier_3_2(train_2,test_2)\n",
    "        finish_time = time.time()\n",
    "    elif (c == 4):\n",
    "        start_time = time.time()\n",
    "        r = G_NB_3_2(train_2,test_2)\n",
    "        finish_time = time.time()\n",
    "    elif (c == 5):\n",
    "        start_time = time.time()\n",
    "        r = Gradient_B_C_3_2(train_2,test_2)\n",
    "        finish_time = time.time()\n",
    "    elif (c == 6):\n",
    "        start_time = time.time()\n",
    "        r = Ada_B_3_2(train_2,test_2)\n",
    "        finish_time = time.time()\n",
    "        \n",
    "    elif (c == 7):\n",
    "        start_time = time.time()\n",
    "        r = SVM_3_2(train_2,test_2)\n",
    "        finish_time = time.time()\n",
    "    \n",
    "    elapsed_time = finish_time - start_time\n",
    "    return r, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf_average(d_1,c_method):\n",
    "    total_time = 0\n",
    "    trials_n = 1\n",
    "    precision_array = []\n",
    "    recall_array = []\n",
    "    accuracy_array = []\n",
    "    f1_score_array = []\n",
    "    fp_rate_array = []\n",
    "    auc_array = []\n",
    "    data = kf_data_split(d_1)\n",
    "    for t in range(trials_n):\n",
    "        print('\\nTrial number:',t+1)\n",
    "        for i in range(len(data)):\n",
    "            print('\\nIteration number:',(i+1))\n",
    "            train_data = data[i][0]\n",
    "            test_data = data[i][1]\n",
    "\n",
    "            total_result = classification_result_2(train_data,test_data,c_method)\n",
    "            result = total_result[0]\n",
    "            total_time += total_result[1]\n",
    "                \n",
    "            precision,recall,accuracy,f1_score,fp_rate = result[0]\n",
    "            auc_result = result[1]\n",
    "\n",
    "            if (precision != 'not_defined'):\n",
    "                precision_array.append(precision)\n",
    "            if (recall != 'not_defined'):\n",
    "                recall_array.append(recall)\n",
    "            if (accuracy != 'not_defined'):\n",
    "                accuracy_array.append(accuracy)\n",
    "            if (f1_score != 'not_defined'):\n",
    "                f1_score_array.append(f1_score)\n",
    "            if (fp_rate != 'not_defined'):\n",
    "                fp_rate_array.append(fp_rate)\n",
    "            if (auc_result != 'not_defined'):\n",
    "                auc_array.append(auc_result)\n",
    "    \n",
    "    precision_array = np.array(precision_array)\n",
    "    recall_array = np.array(recall_array)\n",
    "    accuracy_array = np.array(accuracy_array)\n",
    "    f1_score_array = np.array(f1_score_array)\n",
    "    fp_rate_array = np.array(fp_rate_array)\n",
    "    auc_array = np.array(auc_array)\n",
    "    \n",
    "    print('\\nprecision array:',precision_array,'\\naverage precision:',precision_array.mean(),'\\n')\n",
    "    print('\\nrecall array:',recall_array,'\\naverage recall:',recall_array.mean(),'\\n')\n",
    "    print('\\naccuracy array:',accuracy_array,'\\naverage accuracy:',accuracy_array.mean(),'\\n')\n",
    "    print('\\nf1_score array:',f1_score_array,'\\naverage f1_score:',f1_score_array.mean(),'\\n')\n",
    "    print('\\nfp_rate array:',fp_rate_array,'\\naverage fp_rate:',fp_rate_array.mean(),'\\n')\n",
    "    print('\\nauc array:',auc_array,'\\naverage auc:',auc_array.mean(),'\\n')\n",
    "    \n",
    "    print('precision:',round(precision_array.mean(),4))\n",
    "    print('recall:',round(recall_array.mean(),4))\n",
    "    print('accuracy:',round(accuracy_array.mean(),4))\n",
    "    print('f1 score:',round(f1_score_array.mean(),4))\n",
    "    print('fp rate:',round(fp_rate_array.mean(),4))\n",
    "    print('auc:',round(auc_array.mean(),4))\n",
    "    print('Total time',round(total_time,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1\n",
    "m_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1\n",
    "\n",
    "print('AST4:')\n",
    "print('\\n\\nProbability:')\n",
    "a = kf_average(d_4_p,c1)\n",
    "\n",
    "print('Word:')\n",
    "print('\\n\\nProbability:')\n",
    "a = kf_average(d_5_p,c1)\n",
    "\n",
    "d_6_p = c_1(d_4_p,d_5_p)\n",
    "print('Combination:')\n",
    "print('\\n\\nProbability:')\n",
    "a = kf_average(d_6_p,c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ant\n",
    "threshold = 0.2052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jEdit\n",
    "threshold = 0.1623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi\n",
    "threshold = 0.5130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xalan\n",
    "threshold = 0.5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigrams\n",
    "path_1 = 'D:/SW_defect_prediction_data/'\n",
    "\n",
    "path_2 = 'poi'\n",
    "\n",
    "path_3 = os.path.join(path_1,path_2)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_AST1.npy')\n",
    "b_1_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_c_AST1.npy')\n",
    "b_1_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_AST2.npy')\n",
    "b_2_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_c_AST2.npy')\n",
    "b_2_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_AST3.npy')\n",
    "b_3_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_c_AST3.npy')\n",
    "b_3_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_AST4.npy')\n",
    "b_4_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_c_AST4.npy')\n",
    "b_4_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data.npy')\n",
    "b_5_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_c.npy')\n",
    "b_5_c = np.load(path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_1_b = convert_to_binary(b_1_c)\n",
    "b_2_b = convert_to_binary(b_2_c)\n",
    "b_3_b = convert_to_binary(b_3_c)\n",
    "b_4_b = convert_to_binary(b_4_c)\n",
    "b_5_b = convert_to_binary(b_5_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_1_p.shape)\n",
    "print(b_1_c.shape)\n",
    "print(b_2_p.shape)\n",
    "print(b_2_c.shape)\n",
    "print(b_3_p.shape)\n",
    "print(b_3_c.shape)\n",
    "print(b_4_p.shape)\n",
    "print(b_4_c.shape)\n",
    "print(b_5_p.shape)\n",
    "print(b_5_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ant\n",
    "threshold = 0.2052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jEdit\n",
    "threshold = 0.1623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi\n",
    "threshold = 0.5130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xalan\n",
    "threshold = 0.5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigrams\n",
    "path_1 = 'D:/SW_defect_prediction_data/'\n",
    "\n",
    "path_2 = 'poi'\n",
    "\n",
    "path_3 = os.path.join(path_1,path_2)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_AST1.npy')\n",
    "d_1_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c_AST1.npy')\n",
    "d_1_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_AST2.npy')\n",
    "d_2_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c_AST2.npy')\n",
    "d_2_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_AST3.npy')\n",
    "d_3_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c_AST3.npy')\n",
    "d_3_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_AST4.npy')\n",
    "d_4_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c_AST4.npy')\n",
    "d_4_c = np.load(path_4)\n",
    "\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data.npy')\n",
    "d_5_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c.npy')\n",
    "d_5_c = np.load(path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1_b = convert_to_binary(d_1_c)\n",
    "d_2_b = convert_to_binary(d_2_c)\n",
    "d_3_b = convert_to_binary(d_3_c)\n",
    "d_4_b = convert_to_binary(d_4_c)\n",
    "d_5_b = convert_to_binary(d_5_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_1_p.shape)\n",
    "print(d_1_c.shape)\n",
    "print(d_1_b.shape)\n",
    "\n",
    "print(d_2_p.shape)\n",
    "print(d_2_c.shape)\n",
    "print(d_2_b.shape)\n",
    "\n",
    "print(d_3_p.shape)\n",
    "print(d_3_c.shape)\n",
    "print(d_3_b.shape)\n",
    "\n",
    "print(d_4_p.shape)\n",
    "print(d_4_c.shape)\n",
    "print(d_4_b.shape)\n",
    "\n",
    "print(d_5_p.shape)\n",
    "print(d_5_c.shape)\n",
    "print(d_5_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xalan\n",
    "np.random.seed(0)\n",
    "index_list = np.random.choice(3304,1700,replace=False)\n",
    "\n",
    "d_1_p = d_1_p[index_list]\n",
    "d_1_c = d_1_c[index_list]\n",
    "\n",
    "d_2_p = d_2_p[index_list]\n",
    "d_2_c = d_2_c[index_list]\n",
    "\n",
    "d_3_p = d_3_p[index_list]\n",
    "d_3_c = d_3_c[index_list]\n",
    "\n",
    "d_4_p = d_4_p[index_list]\n",
    "d_4_c = d_4_c[index_list]\n",
    "\n",
    "d_5_p = d_5_p[index_list]\n",
    "d_5_c = d_5_c[index_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print multiple plots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One classification method_multiple projects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_name = ['Ant','jEdit','POI','Xalan']\n",
    "path_1 = \"./data_2/results/\"\n",
    "def print_interval(file_names):\n",
    "    for i in range(4):\n",
    "        path_2 = join(path_1,file_names[i])\n",
    "        with open(path_2,\"rb\") as fp:\n",
    "            result = pickle.load(fp)\n",
    "        \n",
    "        features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result\n",
    "        \n",
    "        min_AST1 = np.min((np.min(auc_array_p_AST1),np.min(auc_array_c_AST1),np.min(auc_array_b_AST1)))\n",
    "        max_AST1 = np.max((np.max(auc_array_p_AST1),np.max(auc_array_c_AST1),np.max(auc_array_b_AST1)))\n",
    "        \n",
    "        min_AST2 = np.min((np.min(auc_array_p_AST2),np.min(auc_array_c_AST2),np.min(auc_array_b_AST2)))\n",
    "        max_AST2 = np.max((np.max(auc_array_p_AST2),np.max(auc_array_c_AST2),np.max(auc_array_b_AST2)))\n",
    "        \n",
    "        min_AST3 = np.min((np.min(auc_array_p_AST3),np.min(auc_array_c_AST3),np.min(auc_array_b_AST3)))\n",
    "        max_AST3 = np.max((np.max(auc_array_p_AST3),np.max(auc_array_c_AST3),np.max(auc_array_b_AST3)))\n",
    "        \n",
    "        min_AST4 = np.min((np.min(auc_array_p_AST4),np.min(auc_array_c_AST4),np.min(auc_array_b_AST4)))\n",
    "        max_AST4 = np.max((np.max(auc_array_p_AST4),np.max(auc_array_c_AST4),np.max(auc_array_b_AST4)))\n",
    "        \n",
    "        min_word = np.min((np.min(auc_array_p_word),np.min(auc_array_c_word),np.min(auc_array_b_word)))\n",
    "        max_word = np.max((np.max(auc_array_p_word),np.max(auc_array_c_word),np.max(auc_array_b_word)))\n",
    "        \n",
    "        min_1 = np.min((min_AST1,min_AST2,min_AST3,min_AST4,min_word))\n",
    "        max_1 = np.max((max_AST1,max_AST2,max_AST3,max_AST4,max_word))\n",
    "        \n",
    "        print('\\nFinal result:',p_name[i],min_1,max_1)\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['ant_LR_trigrams_chi2.txt','jEdit_LR_trigrams_chi2.txt','poi_LR_trigrams_chi2.txt','xalan_LR_trigrams_chi2.txt']\n",
    "a = print(print_interval(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['ant_RF_trigrams_chi2.txt','jEdit_RF_trigrams_chi2.txt','poi_RF_trigrams_chi2.txt','xalan_RF_trigrams_chi2.txt']\n",
    "a = print(print_interval(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['ant_LR_trigrams_FE.txt','jEdit_LR_trigrams_FE.txt','poi_LR_trigrams_FE.txt','xalan_LR_trigrams_FE.txt']\n",
    "a = print(print_interval(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2, LR\n",
    "file_names = ['ant_LR_trigrams_chi2.txt','jEdit_LR_trigrams_chi2.txt','poi_LR_trigrams_chi2.txt','xalan_LR_trigrams_chi2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2, RF\n",
    "file_names = ['ant_RF_trigrams_chi2.txt','jEdit_RF_trigrams_chi2.txt','poi_RF_trigrams_chi2.txt','xalan_RF_trigrams_chi2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FE, LR\n",
    "file_names = ['ant_LR_trigrams_FE.txt','jEdit_LR_trigrams_FE.txt','poi_LR_trigrams_FE.txt','xalan_LR_trigrams_FE.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(4,figsize=(9,17))\n",
    "plt.rcParams.update({'font.size':10})\n",
    "path_1 = \"./data_2/results/\"\n",
    "p_name = ['Ant','jEdit','POI','Xalan']\n",
    "intervals = [[0.58,0.84],[0.63,0.9],[0.55,0.74],[0.58,0.84]]\n",
    "for i in range(4):\n",
    "    path_2 = join(path_1,file_names[i])\n",
    "    with open(path_2,\"rb\") as fp:\n",
    "        result = pickle.load(fp)\n",
    "    features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result\n",
    "\n",
    "    a[i].plot(features_n,auc_array_b_AST1,color='magenta',marker='o',markersize=5,linestyle='dotted',label='Level-order AST, binary')\n",
    "\n",
    "    a[i].plot(features_n,auc_array_b_AST2,color='grey',marker='o',markersize=5,linestyle='dotted',label='Pre-order AST, binary')\n",
    "\n",
    "    a[i].plot(features_n,auc_array_b_AST3,color='firebrick',marker='o',markersize=5,linestyle='dotted',label='Post-order AST, binary')\n",
    "\n",
    "    a[i].plot(features_n,auc_array_b_AST4,color='blue',marker='o',markersize=5,linestyle='dotted',label='Path-based AST, binary')\n",
    "\n",
    "    a[i].plot(features_n,auc_array_b_word,color='black',marker='o',markersize=5,linestyle='dotted',label='Word level, binary')\n",
    "    \n",
    "    a[i].set_title(p_name[i] + ' project',fontsize=18)\n",
    "    a[i].set_xlabel('Number of features',fontsize=14)\n",
    "    a[i].set_ylabel('AUC',fontsize=14)\n",
    "    a[i].set_ylim(intervals[i])\n",
    "\n",
    "a[0].legend(fontsize=12,loc=(0.14,1.25),ncol = 2)\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One project_multiple classification method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['jEdit_LR_trigrams_chi2.txt','jEdit_RF_trigrams_chi2.txt','jEdit_GNB_trigrams_chi2.txt','jEdit_Ada_B_trigrams_chi2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['ant_LR_trigrams_chi2.txt','ant_RF_trigrams_chi2.txt','ant_GNB_trigrams_chi2.txt','ant_Ada_B_trigrams_chi2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['poi_LR_trigrams_chi2.txt','poi_RF_trigrams_chi2.txt','poi_GNB_trigrams_chi2.txt','poi_Ada_B_trigrams_chi2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(4,figsize=(9,12))\n",
    "path_1 = \"./data_2/results/\"\n",
    "\n",
    "p_name = ['Logistic Regression Classifier','Random Forest Classifier','Gaussian Naive Bayes Classifier','Ada-Boost Classifier']\n",
    "for i in range(4):\n",
    "    path_2 = join(path_1,file_names[i])\n",
    "    with open(path_2,\"rb\") as fp:\n",
    "        result = pickle.load(fp)\n",
    "    features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result\n",
    "\n",
    "    a[i].plot(features_n,auc_array_p_AST4,color='blue',marker='o',markersize=5,label='Path-based AST, probability')\n",
    "    a[i].plot(features_n,auc_array_c_AST4,color='blue',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Path-based AST, count')\n",
    "    a[i].plot(features_n,auc_array_b_AST4,color='blue',marker='o',markersize=5,linestyle='dotted',label='Path-based AST, binary')\n",
    "    \n",
    "    a[i].set_title(p_name[i],fontsize=18)\n",
    "\n",
    "    a[i].set_xlabel('Number of features',fontsize=14)\n",
    "    a[i].set_ylabel('AUC',fontsize=14)\n",
    "\n",
    "a[0].legend(fontsize=14,loc=(0.08,1.25),ncol = 2)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different feature selection methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [['ant_LR_trigrams_RFE.txt', 'ant_LR_trigrams_chi2.txt'],['jEdit_LR_trigrams_RFE.txt', 'jEdit_LR_trigrams_chi2.txt'],['poi_LR_trigrams_RFE.txt', 'poi_LR_trigrams_chi2.txt'],['xalan_LR_trigrams_RFE.txt', 'xalan_LR_trigrams_chi2.txt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(4,2,figsize=(20,18))\n",
    "path_1 = \"./data_2/results/\"\n",
    "\n",
    "p_name = ['ant','jEdit','poi','xalan']\n",
    "for i in range(4):\n",
    "    for j in range(2):\n",
    "        path_2 = join(path_1,file_names[i][j])\n",
    "        with open(path_2,\"rb\") as fp:\n",
    "            result = pickle.load(fp)\n",
    "        features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result\n",
    "\n",
    "        a[i,j].plot(features_n,auc_array_p_AST1,color='magenta',marker='o',markersize=5,label='Level-order AST, probability')\n",
    "    \n",
    "        a[i,j].plot(features_n,auc_array_p_AST2,color='grey',marker='o',markersize=5,label='Pre-order AST, probability')\n",
    "    \n",
    "        a[i,j].plot(features_n,auc_array_p_AST3,color='firebrick',marker='o',markersize=5,label='Post-order AST, probability')\n",
    "    \n",
    "        a[i,j].plot(features_n,auc_array_p_AST4,color='blue',marker='o',markersize=5,label='Path-based AST, probability')\n",
    "    \n",
    "        a[i,j].plot(features_n,auc_array_p_word,color='black',marker='o',markersize=5,label='Word level, probability')\n",
    "\n",
    "        if (j == 0):\n",
    "            m_1 = 'RFE'\n",
    "        else:\n",
    "            m_1 = 'Chi2'\n",
    "            \n",
    "        a[i,j].set_title(p_name[i] + ' project' + '_' + str(m_1),fontsize=18)\n",
    "        a[i,j].set_xlabel('Number of features',fontsize=14)\n",
    "        a[i,j].set_ylabel('AUC',fontsize=14)\n",
    "\n",
    "a[0,0].legend(fontsize=14,loc=(0.40,1.20),ncol =3)\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "fig.subplots_adjust(wspace = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability, count, binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [['jEdit_LR_trigrams_chi2.txt', 'poi_LR_trigrams_chi2.txt'],['jEdit_RF_trigrams_chi2.txt', 'poi_RF_trigrams_chi2.txt'],['jEdit_GNB_trigrams_chi2.txt', 'poi_GNB_trigrams_chi2.txt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(3,2,figsize=(20,13))\n",
    "plt.rcParams.update({'font.size':10})\n",
    "path_1 = \"./data_2/results/\"\n",
    "intervals_2 = [[0.63,0.9],[0.55,0.74]]\n",
    "\n",
    "p_name = ['Logistic Regression Classifier','Random Forest Classifier','Gaussian Naive Bayes Classifier']\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        path_2 = join(path_1,file_names[i][j])\n",
    "        with open(path_2,\"rb\") as fp:\n",
    "            result = pickle.load(fp)\n",
    "        features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result\n",
    "\n",
    "        a[i,j].plot(features_n,auc_array_p_AST4,color='blue',marker='o',markersize=5,label='Path-based AST, probability')\n",
    "        a[i,j].plot(features_n,auc_array_c_AST4,color='blue',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Path-based AST, count')\n",
    "        a[i,j].plot(features_n,auc_array_b_AST4,color='blue',marker='o',markersize=5,linestyle='dotted',label='Path-based AST, binary')\n",
    "\n",
    "        if (j == 0):\n",
    "            m_1 = 'jEdit'\n",
    "        else:\n",
    "            m_1 = 'POI'\n",
    "            \n",
    "        a[i,j].set_title(p_name[i] + ', ' + str(m_1) + ' project',fontsize=18)\n",
    "        a[i,j].set_xlabel('Number of features',fontsize=14)\n",
    "        a[i,j].set_ylabel('AUC',fontsize=14)\n",
    "        \n",
    "        a[i,j].set_ylim(intervals_2[j])\n",
    "\n",
    "a[0,0].legend(fontsize=12,loc=(0.40,1.20),ncol =3)\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "fig.subplots_adjust(wspace = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [['jEdit_LR_trigrams_chi2.txt', 'poi_LR_trigrams_chi2.txt'],['jEdit_RF_trigrams_chi2.txt', 'poi_RF_trigrams_chi2.txt'],['jEdit_GNB_trigrams_chi2.txt', 'poi_GNB_trigrams_chi2.txt'],['jEdit_Ada_B_trigrams_chi2.txt', 'poi_Ada_B_trigrams_chi2.txt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, a = plt.subplots(4,2,figsize=(20,18))\n",
    "path_1 = \"./data_2/results/\"\n",
    "\n",
    "p_name = ['Logistic Regression Classifier','Random Forest Classifier','Gaussian Naive Bayes Classifier','Ada-Boost Classifier']\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(2):\n",
    "        path_2 = join(path_1,file_names[i][j])\n",
    "        with open(path_2,\"rb\") as fp:\n",
    "            result = pickle.load(fp)\n",
    "        features_n,auc_array_p_AST1,auc_array_c_AST1,auc_array_b_AST1,auc_array_p_AST2,auc_array_c_AST2,auc_array_b_AST2,auc_array_p_AST3,auc_array_c_AST3,auc_array_b_AST3,auc_array_p_AST4,auc_array_c_AST4,auc_array_b_AST4,auc_array_p_word,auc_array_c_word,auc_array_b_word = result\n",
    "\n",
    "        a[i,j].plot(features_n,auc_array_p_AST4,color='blue',marker='o',markersize=5,label='Path-based AST, probability')\n",
    "        a[i,j].plot(features_n,auc_array_c_AST4,color='blue',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Path-based AST, count')\n",
    "        a[i,j].plot(features_n,auc_array_b_AST4,color='blue',marker='o',markersize=5,linestyle='dotted',label='Path-based AST, binary')\n",
    "\n",
    "        if (j == 0):\n",
    "            m_1 = 'jEdit'\n",
    "        else:\n",
    "            m_1 = 'poi'\n",
    "            \n",
    "        a[i,j].set_title(p_name[i] + ', ' + str(m_1) + ' project',fontsize=18)\n",
    "        a[i,j].set_xlabel('Number of features',fontsize=14)\n",
    "        a[i,j].set_ylabel('AUC',fontsize=14)\n",
    "\n",
    "a[0,0].legend(fontsize=14,loc=(0.40,1.20),ncol =3)\n",
    "fig.subplots_adjust(hspace = 0.4)\n",
    "fig.subplots_adjust(wspace = 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram, Bigram, Combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = 'D:/SW_defect_prediction_data/'\n",
    "\n",
    "path_2 = 'ant'\n",
    "\n",
    "path_3 = os.path.join(path_1,path_2)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_AST4.npy')\n",
    "b_4_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_bigram_data_c_AST4.npy')\n",
    "b_4_c = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_AST4.npy')\n",
    "d_4_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c_AST4.npy')\n",
    "d_4_c = np.load(path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = 'D:/SW_defect_prediction_data/'\n",
    "\n",
    "path_2 = 'jEdit'\n",
    "\n",
    "path_3 = os.path.join(path_1,path_2)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_AST4.npy')\n",
    "b_4_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c_AST4.npy')\n",
    "b_4_c = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data.npy')\n",
    "d_4_p = np.load(path_4)\n",
    "\n",
    "path_4 = os.path.join(path_3,'dense_trigram_data_c.npy')\n",
    "d_4_c = np.load(path_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_chi2_2(data_1,data_2,data_3,data_4,c_method):\n",
    "    \n",
    "    d_1 = data_1.copy()\n",
    "    d_2 = data_2.copy()\n",
    "    d_3 = data_3.copy()\n",
    "    d_4 = data_4.copy()\n",
    "    d_5 = c_1(d_1,d_3)\n",
    "    d_6 = c_1(d_2,d_4)\n",
    "    \n",
    "    print(d_5.shape)\n",
    "    print(d_6.shape)\n",
    "    \n",
    "    train_1_p, test_1_p = split_data_2(d_1)\n",
    "    train_1_c, test_1_c = split_data_2(d_2)\n",
    "\n",
    "    train_2_p, test_2_p = split_data_2(d_3)\n",
    "    train_2_c, test_2_c = split_data_2(d_4)\n",
    "    \n",
    "    train_3_p, test_3_p = split_data_2(d_5)\n",
    "    train_3_c, test_3_c = split_data_2(d_6)\n",
    "\n",
    "    features_n = []\n",
    "    \n",
    "    auc_array_p_bigram = []\n",
    "    auc_array_c_bigram = []\n",
    "    auc_array_b_bigram = []\n",
    "    \n",
    "    auc_array_p_trigram = []\n",
    "    auc_array_c_trigram = []\n",
    "    auc_array_b_trigram = []\n",
    "    \n",
    "    auc_array_p_combination = []\n",
    "    auc_array_c_combination = []\n",
    "    auc_array_b_combination = []\n",
    "\n",
    "    score_f_type = 2\n",
    "    \n",
    "    print('Start training')\n",
    "    feature_s_1 = select_features_2(train_1_p,400,score_f_type)\n",
    "    print('Stop training')\n",
    "    \n",
    "    i_max = 400\n",
    "    for i in range(i_max,24,-25):\n",
    "        print(i)\n",
    "        features_n.append(i)\n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_1_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_p_2 = feature_s[0]\n",
    "        length_1 = test_1_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_p_2 = test_1_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_1_p_2,test_1_p_2,c_method)[1]\n",
    "        auc_array_p_bigram.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('bigram_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_1_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_c_2 = feature_s[0]\n",
    "        length_1 = test_1_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_c_2 = test_1_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_1_c_2,test_1_c_2,c_method)[1]\n",
    "        auc_array_c_bigram.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('bigram_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_1_c_3 = train_1_c_2.copy()\n",
    "        test_1_c_3 = test_1_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_1_c_3)\n",
    "        b_test_data = convert_to_binary(test_1_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_bigram.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_2_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_p_2 = feature_s[0]\n",
    "        length_1 = test_2_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_p_2 = test_2_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_2_p_2,test_2_p_2,c_method)[1]\n",
    "        auc_array_p_trigram.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('trigram_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_2_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_c_2 = feature_s[0]\n",
    "        length_1 = test_2_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_c_2 = test_2_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_2_c_2,test_2_c_2,c_method)[1]\n",
    "        auc_array_c_trigram.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('trigram_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_2_c_3 = train_2_c_2.copy()\n",
    "        test_2_c_3 = test_2_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_2_c_3)\n",
    "        b_test_data = convert_to_binary(test_2_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_trigram.append(auc_value_b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_3_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_p_2 = feature_s[0]\n",
    "        length_1 = test_3_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_p_2 = test_3_p[:,columns_1]\n",
    "        auc_value_p = classification_result(train_3_p_2,test_3_p_2,c_method)[1]\n",
    "        auc_array_p_combination.append(auc_value_p)\n",
    "        if (i == i_max):\n",
    "            print('combination_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_3_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_c_2 = feature_s[0]\n",
    "        length_1 = test_3_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_c_2 = test_3_c[:,columns_1]\n",
    "        auc_value_c = classification_result(train_3_c_2,test_3_c_2,c_method)[1]\n",
    "        auc_array_c_combination.append(auc_value_c)\n",
    "        if (i == i_max):\n",
    "            print('combination_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_3_c_3 = train_3_c_2.copy()\n",
    "        test_3_c_3 = test_3_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_3_c_3)\n",
    "        b_test_data = convert_to_binary(test_3_c_3)\n",
    "        auc_value_b = classification_result(b_train_data,b_test_data,c_method)[1]\n",
    "        auc_array_b_combination.append(auc_value_b)\n",
    "        \n",
    "    return(features_n,auc_array_p_bigram,auc_array_c_bigram,auc_array_b_bigram,auc_array_p_trigram,auc_array_c_trigram,auc_array_b_trigram,auc_array_p_combination,auc_array_c_combination,auc_array_b_combination)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "result = Evaluation_chi2_2(b_4_p,b_4_c,d_4_p,d_4_c,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n,auc_array_p_bigram,auc_array_c_bigram,auc_array_b_bigram,auc_array_p_trigram,auc_array_c_trigram,auc_array_b_trigram,auc_array_p_combination,auc_array_c_combination,auc_array_b_combination = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    " \n",
    "plt.plot(features_n,auc_array_p_bigram,color='skyblue',marker='o',markersize=5,label='Level-order AST, probability')\n",
    "plt.plot(features_n,auc_array_c_bigram,color='skyblue',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Level-order AST, count')\n",
    "plt.plot(features_n,auc_array_b_bigram,color='skyblue',marker='o',markersize=5,linestyle='dotted',label='Level-order AST, binary')\n",
    "\n",
    "plt.plot(features_n,auc_array_p_trigram,color='blue',marker='o',markersize=5,label='Pre-order AST, probability')\n",
    "plt.plot(features_n,auc_array_c_trigram,color='blue',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Pre-order AST, count')\n",
    "plt.plot(features_n,auc_array_b_trigram,color='blue',marker='o',markersize=5,linestyle='dotted',label='Pre-order AST, binary')\n",
    "\n",
    "plt.plot(features_n,auc_array_p_combination,color='brown',marker='o',markersize=5,label='Post-order AST, probability')\n",
    "plt.plot(features_n,auc_array_c_combination,color='brown',marker='o',markersize=5,linestyle='--',dashes=(3,3),label='Post-order AST, count')\n",
    "plt.plot(features_n,auc_array_b_combination,color='brown',marker='o',markersize=5,linestyle='dotted',label='Post-order AST, binary')\n",
    "\n",
    "\n",
    "\n",
    "plt.title('AUC per number of features',fontsize=16)\n",
    "plt.xlabel('Number of features',fontsize=14)\n",
    "plt.ylabel('AUC',fontsize=14)\n",
    "axes = plt.gca()\n",
    "plt.gca().legend(loc='center left', bbox_to_anchor=(1,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,5)\n",
    "plt.rcParams.update({'font.size':14})\n",
    "fig = plt.figure()\n",
    "a = fig.add_axes([0,0,1,1])\n",
    "methods = ['Word-level','Level-order AST','Pre-order AST','Post-order AST','Path-based AST']\n",
    "\n",
    "trigrams_n = [4409,11828,3659,4101,1809]\n",
    "a.bar(methods,trigrams_n,color = 'blue')\n",
    "a.set_ylabel('Number of trifram types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using linear SVM (accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kf_average_accuracy(d_1,c_method):\n",
    "    c_method = 7\n",
    "    total_time = 0\n",
    "    trials_n = 1\n",
    "    precision_array = []\n",
    "    recall_array = []\n",
    "    accuracy_array = []\n",
    "    f1_score_array = []\n",
    "    fp_rate_array = []\n",
    "    \n",
    "    data = kf_data_split(d_1)\n",
    "    for t in range(trials_n):\n",
    "        print('\\nTrial number:',t+1)\n",
    "        for i in range(len(data)):\n",
    "            print('\\nIteration number:',(i+1))\n",
    "            train_data = data[i][0]\n",
    "            test_data = data[i][1]\n",
    "\n",
    "            total_result = classification_result_2(train_data,test_data,c_method)\n",
    "            result = total_result[0]\n",
    "            total_time += total_result[1]\n",
    "                \n",
    "            precision,recall,accuracy,f1_score,fp_rate = result\n",
    "            \n",
    "\n",
    "            if (precision != 'not_defined'):\n",
    "                precision_array.append(precision)\n",
    "            if (recall != 'not_defined'):\n",
    "                recall_array.append(recall)\n",
    "            if (accuracy != 'not_defined'):\n",
    "                accuracy_array.append(accuracy)\n",
    "            if (f1_score != 'not_defined'):\n",
    "                f1_score_array.append(f1_score)\n",
    "            if (fp_rate != 'not_defined'):\n",
    "                fp_rate_array.append(fp_rate)\n",
    "            \n",
    "    \n",
    "    precision_array = np.array(precision_array)\n",
    "    recall_array = np.array(recall_array)\n",
    "    accuracy_array = np.array(accuracy_array)\n",
    "    f1_score_array = np.array(f1_score_array)\n",
    "    fp_rate_array = np.array(fp_rate_array)\n",
    "    \n",
    "    print('\\nprecision array:',precision_array,'\\naverage precision:',precision_array.mean(),'\\n')\n",
    "    print('\\nrecall array:',recall_array,'\\naverage recall:',recall_array.mean(),'\\n')\n",
    "    print('\\naccuracy array:',accuracy_array,'\\naverage accuracy:',accuracy_array.mean(),'\\n')\n",
    "    print('\\nf1_score array:',f1_score_array,'\\naverage f1_score:',f1_score_array.mean(),'\\n')\n",
    "    print('\\nfp_rate array:',fp_rate_array,'\\naverage fp_rate:',fp_rate_array.mean(),'\\n')\n",
    "    \n",
    "    print('precision:',round(precision_array.mean(),4))\n",
    "    print('recall:',round(recall_array.mean(),4))\n",
    "    print('accuracy:',round(accuracy_array.mean(),4))\n",
    "    print('f1 score:',round(f1_score_array.mean(),4))\n",
    "    print('fp rate:',round(fp_rate_array.mean(),4))\n",
    "    print('Total time',round(total_time,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 7\n",
    "print('AST4:')\n",
    "print('\\n\\nProbability:')\n",
    "a = kf_average_accuracy(d_4_p,c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi2 for accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation_chi2_accuracy(data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,data_10,c_method):\n",
    "    d_1 =data_1.copy()\n",
    "    d_2 =data_2.copy()\n",
    "    d_3 =data_3.copy()\n",
    "    d_4 =data_4.copy()\n",
    "    d_5 =data_5.copy()\n",
    "    d_6 =data_6.copy()\n",
    "    d_7 =data_7.copy()\n",
    "    d_8 =data_8.copy()\n",
    "    d_9 =data_9.copy()\n",
    "    d_10 =data_10.copy()\n",
    "    \n",
    "    train_1_p, test_1_p = split_data_2(d_1)\n",
    "    train_1_c, test_1_c = split_data_2(d_2)\n",
    "\n",
    "    train_2_p, test_2_p = split_data_2(d_3)\n",
    "    train_2_c, test_2_c = split_data_2(d_4)\n",
    "\n",
    "    train_3_p, test_3_p = split_data_2(d_5)\n",
    "    train_3_c, test_3_c = split_data_2(d_6)\n",
    "\n",
    "    train_4_p, test_4_p = split_data_2(d_7)\n",
    "    train_4_c, test_4_c = split_data_2(d_8)\n",
    "\n",
    "    train_5_p, test_5_p = split_data_2(d_9)\n",
    "    train_5_c, test_5_c = split_data_2(d_10)\n",
    "\n",
    "\n",
    "    features_n = []\n",
    "    \n",
    "    accuracy_array_p_AST1 = []\n",
    "    accuracy_array_c_AST1 = []\n",
    "    accuracy_array_b_AST1 = []\n",
    "    \n",
    "    accuracy_array_p_AST2 = []\n",
    "    accuracy_array_c_AST2 = []\n",
    "    accuracy_array_b_AST2 = []\n",
    "    \n",
    "    accuracy_array_p_AST3 = []\n",
    "    accuracy_array_c_AST3 = []\n",
    "    accuracy_array_b_AST3 = []\n",
    "    \n",
    "    accuracy_array_p_AST4 = []\n",
    "    accuracy_array_c_AST4 = []\n",
    "    accuracy_array_b_AST4 = []\n",
    "    \n",
    "    accuracy_array_p_word = []\n",
    "    accuracy_array_c_word = []\n",
    "    accuracy_array_b_word = []\n",
    "\n",
    "    score_f_type = 2\n",
    "    \n",
    "    \n",
    "    i_max = 500\n",
    "    for i in range(i_max,24,-25):\n",
    "#     for i in range(i_max,i_max-1,-25):\n",
    "        print(i)\n",
    "        features_n.append(i)\n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_1_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_p_2 = feature_s[0]\n",
    "        length_1 = test_1_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_p_2 = test_1_p[:,columns_1]\n",
    "        result_p = classification_result(train_1_p_2,test_1_p_2,c_method)\n",
    "        accuracy_array_p_AST1.append(result_p[2])\n",
    "        if (i == i_max):\n",
    "            print('AST1_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_1_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_1_c_2 = feature_s[0]\n",
    "        length_1 = test_1_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_1_c_2 = test_1_c[:,columns_1]\n",
    "        result_c = classification_result(train_1_c_2,test_1_c_2,c_method)\n",
    "        accuracy_array_c_AST1.append(result_c[2])\n",
    "        if (i == i_max):\n",
    "            print('AST1_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_1_c_3 = train_1_c_2.copy()\n",
    "        test_1_c_3 = test_1_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_1_c_3)\n",
    "        b_test_data = convert_to_binary(test_1_c_3)\n",
    "        result_b = classification_result(b_train_data,b_test_data,c_method)\n",
    "        accuracy_array_b_AST1.append(result_b[2])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_2_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_p_2 = feature_s[0]\n",
    "        length_1 = test_2_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_p_2 = test_2_p[:,columns_1]\n",
    "        result_p = classification_result(train_2_p_2,test_2_p_2,c_method)\n",
    "        accuracy_array_p_AST2.append(result_p[2])\n",
    "        if (i == i_max):\n",
    "            print('AST2_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_2_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_2_c_2 = feature_s[0]\n",
    "        length_1 = test_2_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_2_c_2 = test_2_c[:,columns_1]\n",
    "        result_c = classification_result(train_2_c_2,test_2_c_2,c_method)\n",
    "        accuracy_array_c_AST2.append(result_c[2])\n",
    "        if (i == i_max):\n",
    "            print('AST2_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_2_c_3 = train_2_c_2.copy()\n",
    "        test_2_c_3 = test_2_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_2_c_3)\n",
    "        b_test_data = convert_to_binary(test_2_c_3)\n",
    "        result_b = classification_result(b_train_data,b_test_data,c_method)\n",
    "        accuracy_array_b_AST2.append(result_b[2])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_3_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_p_2 = feature_s[0]\n",
    "        length_1 = test_3_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_p_2 = test_3_p[:,columns_1]\n",
    "        result_p = classification_result(train_3_p_2,test_3_p_2,c_method)\n",
    "        accuracy_array_p_AST3.append(result_p[2])\n",
    "        if (i == i_max):\n",
    "            print('AST3_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_3_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_3_c_2 = feature_s[0]\n",
    "        length_1 = test_3_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_3_c_2 = test_3_c[:,columns_1]\n",
    "        result_c = classification_result(train_3_c_2,test_3_c_2,c_method)\n",
    "        accuracy_array_c_AST3.append(result_c[2])\n",
    "        if (i == i_max):\n",
    "            print('AST3_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_3_c_3 = train_3_c_2.copy()\n",
    "        test_3_c_3 = test_3_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_3_c_3)\n",
    "        b_test_data = convert_to_binary(test_3_c_3)\n",
    "        result_b = classification_result(b_train_data,b_test_data,c_method)\n",
    "        accuracy_array_b_AST3.append(result_b[2])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_4_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_p_2 = feature_s[0]\n",
    "        length_1 = test_4_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_p_2 = test_4_p[:,columns_1]\n",
    "        result_p = classification_result(train_4_p_2,test_4_p_2,c_method)\n",
    "        accuracy_array_p_AST4.append(result_p[2])\n",
    "        if (i == i_max):\n",
    "            print('AST4_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        feature_s = select_features_2(train_4_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_4_c_2 = feature_s[0]\n",
    "        length_1 = test_4_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_4_c_2 = test_4_c[:,columns_1]\n",
    "        result_c = classification_result(train_4_c_2,test_4_c_2,c_method)\n",
    "        accuracy_array_c_AST4.append(result_c[2])\n",
    "        if (i == i_max):\n",
    "            print('AST4_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_4_c_3 = train_4_c_2.copy()\n",
    "        test_4_c_3 = test_4_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_4_c_3)\n",
    "        b_test_data = convert_to_binary(test_4_c_3)\n",
    "        result_b = classification_result(b_train_data,b_test_data,c_method)\n",
    "        accuracy_array_b_AST4.append(result_b[2])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_s = select_features_2(train_5_p,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_5_p_2 = feature_s[0]\n",
    "        length_1 = test_5_p.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_5_p_2 = test_5_p[:,columns_1]\n",
    "        result_p = classification_result(train_5_p_2,test_5_p_2,c_method)\n",
    "        accuracy_array_p_word.append(result_p[2])\n",
    "        if (i == i_max):\n",
    "            print('Word_p:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "            \n",
    "        feature_s = select_features_2(train_5_c,i,score_f_type)\n",
    "        columns_1 = feature_s[1]\n",
    "        train_5_c_2 = feature_s[0]\n",
    "        length_1 = test_5_c.shape[1]\n",
    "        columns_1 = np.append(columns_1,(length_1 - 1))\n",
    "        test_5_c_2 = test_5_c[:,columns_1]\n",
    "        result_c = classification_result(train_5_c_2,test_5_c_2,c_method)\n",
    "        accuracy_array_c_word.append(result_c[2])\n",
    "        if (i == i_max):\n",
    "            print('Word_c:')\n",
    "            print(round(feature_s[2],4),'\\n')\n",
    "        \n",
    "        train_5_c_3 = train_5_c_2.copy()\n",
    "        test_5_c_3 = test_5_c_2.copy()\n",
    "        b_train_data = convert_to_binary(train_5_c_3)\n",
    "        b_test_data = convert_to_binary(test_5_c_3)\n",
    "        result_b = classification_result(b_train_data,b_test_data,c_method)\n",
    "        accuracy_array_b_word.append(result_b[2])\n",
    "            \n",
    "    return(features_n,accuracy_array_p_AST1,accuracy_array_c_AST1,accuracy_array_b_AST1,accuracy_array_p_AST2,accuracy_array_c_AST2,accuracy_array_b_AST2,accuracy_array_p_AST3,accuracy_array_c_AST3,accuracy_array_b_AST3,accuracy_array_p_AST4,accuracy_array_c_AST4,accuracy_array_b_AST4,accuracy_array_p_word,accuracy_array_c_word,accuracy_array_b_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2 Logistic Regression\n",
    "step_value = 25\n",
    "result = Evaluation_chi2_accuracy(d_1_p, d_1_c, d_2_p, d_2_c, d_3_p, d_3_c, d_4_p, d_4_c, d_5_p, d_5_c, 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
